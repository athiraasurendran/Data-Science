# Prompt Engineering

- **Prompt Engineering** is the practice of **designing and refining prompts** to get the best results from AI models, especially **Large Language Models (LLMs)** like GPT.  
- Goal: Make the AI **understand the task correctly** and produce **accurate, relevant, and useful output**.  

---

## Why is Prompt Engineering Important?

- LLMs generate **different outputs based on how the prompt is written**.  
- A well-crafted prompt can:
  - Improve **accuracy and relevance**
  - Reduce **ambiguity**
  - Guide the model for **specific tasks**
  - Save **time and compute resources**

---

## Key Principles of Prompt Engineering

1. **Clarity:** Be specific and clear about the task.  
2. **Context:** Provide relevant background or examples.  
3. **Constraints:** Mention limits like word count, style, or format.  
4. **Step-by-step guidance:** Break complex tasks into smaller steps.  
5. **Examples:** Show input-output pairs to guide the model.  

---

## Types of Prompts

| Prompt Type | Description | Example |
|------------|------------|---------|
| Instructional | Give explicit instructions | "Summarize the following paragraph in 3 sentences." |
| Few-shot | Provide examples in prompt | "Translate English to French. Example: 'Hello' → 'Bonjour'. Translate: 'Good night' → ?" |
| Zero-shot | No examples, just instructions | "Translate 'Good morning' to French." |
| Chain-of-Thought | Guide model step-by-step | "Step 1: Identify key points. Step 2: Summarize." |

---

## Prompt Engineering Techniques

### 1. Zero-shot Prompt
- Model generates output without examples.

```python
from openai import OpenAI

client = OpenAI(api_key="YOUR_API_KEY")
prompt = "Translate the following sentence to Spanish: 'I love data science.'"

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role":"user","content":prompt}]
)

print(response.choices[0].message.content)
```

### 2. Few-shot Prompt

Provide examples to guide the model.
