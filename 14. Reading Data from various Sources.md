# Reading Data from various Sources

## 1. CSV (Comma-Separated Values)

- Most common format.

- Python (pandas):

```python
import pandas as pd

df = pd.read_csv("data.csv")
```

---

## 2. Excel Files (.xls, .xlsx)

- Useful for business datasets.

- Python (pandas):

```python
  df = pd.read_excel("data.xlsx", sheet_name="Sheet1")
```

---

## 3. Text Files (.txt)

- Data stored with delimiters like ,, ;, or \t.

- Python:

```python
  df = pd.read_csv("data.txt", delimiter="\t")  # Tab-delimited file
```

---

## 4. Databases (SQL, MySQL, PostgreSQL, etc.)

- Often large datasets stored in relational databases.

- Python (SQLAlchemy + pandas):

```python
  from sqlalchemy import create_engine

engine = create_engine("mysql+pymysql://user:password@localhost:3306/dbname")
df = pd.read_sql("SELECT * FROM tablename", engine)
```

---

## 5. JSON (JavaScript Object Notation)

- Common for APIs and web data.

- Python:

```python
df = pd.read_json("data.json")
```

---

## 6. APIs (Application Programming Interface)

- To fetch live/real-time data from web services.

- Python (requests + pandas):

```python
import requests

url = "https://api.example.com/data"
response = requests.get(url)
data = response.json()
df = pd.DataFrame(data)
```

---

## 7. Web Scraping

- Extracting data directly from websites.

- Python (BeautifulSoup):

```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com"
html = requests.get(url).text
soup = BeautifulSoup(html, "html.parser")
```

---

## 8. Big Data Sources

- Tools: Hadoop, Spark.

- PySpark Example:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("ReadData").getOrCreate()
df = spark.read.csv("hdfs://path/data.csv", header=True, inferSchema=True)
```

---

